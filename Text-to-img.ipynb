{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7TKfwkldkFV"
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "booFOcBFTA_F"
   },
   "outputs": [],
   "source": [
    "pip install torch==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riaOaXETvZv8"
   },
   "outputs": [],
   "source": [
    "pip install transformers xformers==0.0.29.post3 diffusers pillow opencv-python numpy gradio fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXqHMQZPdFmu"
   },
   "outputs": [],
   "source": [
    "# Higher model\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Use Stable Diffusion 2.1 (More Compatible with Diffusers)\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "# Load the Stable Diffusion model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Enable optimizations\n",
    "pipe.enable_attention_slicing()\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.unet = torch.compile(pipe.unet)\n",
    "\n",
    "# Function to generate an image\n",
    "def generate_image(prompt, steps, guidance):\n",
    "    image = pipe(prompt, num_inference_steps=steps, guidance_scale=guidance).images[0]\n",
    "    return image\n",
    "\n",
    "# Launch Gradio UI with debug mode\n",
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter Prompt\"),\n",
    "        gr.Slider(10, 30, value=20, step=1, label=\"Inference Steps\"),\n",
    "        gr.Slider(1, 10, value=5, step=0.5, label=\"Guidance Scale\")\n",
    "    ],\n",
    "    outputs=\"image\"\n",
    ").launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDXW-G08sjcZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import gradio as gr\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize pipeline with optimized defaults\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None\n",
    ").to(device)\n",
    "\n",
    "# Use optimized DPMSolver++ scheduler\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipe.scheduler.config,\n",
    "    algorithm_type=\"dpmsolver++\",\n",
    "    solver_order=2,\n",
    "    predict_epsilon=True,\n",
    "    thresholding=True,\n",
    "    dynamic_thresholding_ratio=0.995\n",
    ")\n",
    "\n",
    "# Enable all optimizations\n",
    "pipe.enable_attention_slicing(slice_size=\"auto\")\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.enable_vae_slicing()\n",
    "    pipe.enable_sequential_cpu_offload()\n",
    "\n",
    "def calculate_adaptive_guidance(prompt, base_guidance):\n",
    "    \"\"\"Enhanced adaptive guidance calculation\"\"\"\n",
    "    prompt_lower = prompt.lower()\n",
    "    \n",
    "    # Extended guidance factors\n",
    "    style_terms = ['realistic', 'detailed', 'photographic', 'artistic', 'cartoon', 'anime', 'digital art', 'oil painting', 'watercolor', 'sketch', '3d render', 'cinematic', 'studio photo']\n",
    "    color_terms = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'black', 'white', 'golden', 'silver', 'metallic', 'neon', 'pastel', 'vibrant', 'muted']\n",
    "    composition_terms = ['portrait', 'landscape', 'close-up', 'wide shot', 'aerial view', 'side view', 'front view', 'macro', 'ultra wide']\n",
    "    lighting_terms = ['sunlight', 'studio lighting', 'dramatic lighting', 'soft light', 'hard light', 'backlight', 'natural light']\n",
    "    \n",
    "    # Enhanced complexity calculation\n",
    "    complexity = 1.0\n",
    "    complexity += sum(term in prompt_lower for term in style_terms) * 0.35\n",
    "    complexity += sum(term in prompt_lower for term in color_terms) * 0.25\n",
    "    complexity += sum(term in prompt_lower for term in composition_terms) * 0.3\n",
    "    complexity += sum(term in prompt_lower for term in lighting_terms) * 0.3\n",
    "    complexity += len(prompt.split()) * 0.06\n",
    "    \n",
    "    # Optimized guidance scaling\n",
    "    return min(max(base_guidance * complexity, 8.0), 25.0)\n",
    "\n",
    "def generate_image(\n",
    "    prompt,\n",
    "    steps=50,\n",
    "    guidance_base=15,\n",
    "    width=768,\n",
    "    height=768,\n",
    "    seed=-1,\n",
    "    use_adaptive_guidance=True\n",
    "):\n",
    "    # Comprehensive negative prompt\n",
    "    negative_prompt = \"\"\"\n",
    "    # Critical Quality Issues\n",
    "    low quality, worst quality, bad quality, jpeg artifacts, compression artifacts,\n",
    "    blurry, ugly, deformed, mutated, distorted, disfigured, poorly drawn, amateur,\n",
    "    \n",
    "    # Anatomical Issues\n",
    "    (deformed body:1.4), (deformed face:1.4), (deformed limbs:1.4), (bad anatomy:1.4),\n",
    "    bad proportions, wrong proportions, out of proportion, anatomical errors,\n",
    "    extra fingers, missing fingers, fused fingers, too many fingers, mutated hands,\n",
    "    extra limbs, missing limbs, floating limbs, disconnected limbs, broken limbs,\n",
    "    extra joints, missing joints, broken joints, dislocated joints,\n",
    "    \n",
    "    # Duplication and Repetition\n",
    "    (duplicate:1.5), (duplicated:1.5), (cloned:1.5), (repeating:1.5), (multiple:1.5),\n",
    "    (clone artifacts:1.5), (repetitive:1.5), (duplicated elements:1.5),\n",
    "    duplicate faces, cloned faces, multiple faces, copied faces,\n",
    "    duplicate objects, cloned objects, multiple objects, copied objects,\n",
    "    \n",
    "    # Composition and Technical\n",
    "    bad composition, unbalanced composition, poor composition, amateurish composition,\n",
    "    improper perspective, wrong perspective, bad perspective, distorted perspective,\n",
    "    bad foreshortening, incorrect foreshortening, perspective errors,\n",
    "    bad camera angle, wrong camera angle, tilted horizon, crooked horizon,\n",
    "    \n",
    "    # Lighting and Color\n",
    "    bad lighting, harsh lighting, uneven lighting, poor lighting, incorrect shadows,\n",
    "    wrong shadows, missing shadows, inconsistent lighting, lighting errors,\n",
    "    bad exposure, overexposed, underexposed, blown out highlights, crushed blacks,\n",
    "    color bleeding, color artifacts, wrong colors, unnatural colors,\n",
    "    \n",
    "    # Additional Artifacts\n",
    "    watermark, text, signature, logo, timestamp, border, frame,\n",
    "    aliasing, pixelation, noise, grain, banding, moire patterns,\n",
    "    chromatic aberration, lens distortion, vignetting, halation,\n",
    "    \n",
    "    # Style Inconsistencies\n",
    "    inconsistent style, mixed styles, conflicting styles, wrong style,\n",
    "    out of character, style break, aesthetic mismatch, artistic inconsistency\n",
    "    \"\"\".replace('\\n', ' ').replace('    ', '').replace('# ', '')\n",
    "\n",
    "    # Enhanced positive prompt additions\n",
    "    enhancement_prompt = \"\"\"\n",
    "    (masterpiece:1.2), (best quality:1.2), (ultra high resolution:1.2),\n",
    "    (highly detailed:1.1), (sharp focus:1.1), (crystal clear:1.1),\n",
    "    professional photography, studio quality, perfect composition,\n",
    "    accurate proportions, precise details, beautiful lighting,\n",
    "    exquisite texturing, proper anatomy, cohesive style,\n",
    "    8k resolution, ultra HD, ray tracing, physically based rendering,\n",
    "    professional color grading, perfect shadows and highlights\n",
    "    \"\"\".strip()\n",
    "\n",
    "    # Calculate final guidance scale\n",
    "    final_guidance = calculate_adaptive_guidance(prompt, guidance_base) if use_adaptive_guidance else guidance_base\n",
    "\n",
    "    # Set random seed if provided\n",
    "    if seed != -1:\n",
    "        torch.manual_seed(seed)\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    else:\n",
    "        generator = None\n",
    "\n",
    "    # Enhanced prompt weighting\n",
    "    prompt_elements = prompt.split(',')\n",
    "    weighted_prompt = \"\"\n",
    "    for i, element in enumerate(prompt_elements):\n",
    "        element = element.strip()\n",
    "        if i == 0:  # Main subject gets highest emphasis\n",
    "            weighted_prompt += f\"({element}:1.4)\"  # Increased weight for main subject\n",
    "        elif i == 1:  # Secondary elements get medium emphasis\n",
    "            weighted_prompt += f\", ({element}:1.2)\"\n",
    "        else:  # Tertiary elements get normal weight\n",
    "            weighted_prompt += f\", {element}\"\n",
    "\n",
    "    # Generate image with optimized parameters\n",
    "    image = pipe(\n",
    "        weighted_prompt + \", \" + enhancement_prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=final_guidance,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        generator=generator,\n",
    "        num_images_per_prompt=1,\n",
    "    ).images[0]\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Enhanced Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter your prompt\", lines=3, placeholder=\"Describe the image you want to generate...\"),\n",
    "        gr.Slider(30, 150, value=50, step=1, label=\"Quality Steps (higher = better quality)\"),\n",
    "        gr.Slider(7, 30, value=15, step=0.5, label=\"Base Guidance Scale (higher = stronger prompt adherence)\"),\n",
    "        gr.Slider(512, 1024, value=768, step=128, label=\"Width\"),\n",
    "        gr.Slider(512, 1024, value=768, step=128, label=\"Height\"),\n",
    "        gr.Number(label=\"Seed (-1 for random)\", value=-1),\n",
    "        gr.Checkbox(label=\"Use Adaptive Guidance\", value=True, info=\"Automatically adjusts guidance based on prompt complexity\")\n",
    "    ],\n",
    "    outputs=gr.Image(label=\"Generated Image\", type=\"pil\"),\n",
    "    title=\"Professional Stable Diffusion Generator\",\n",
    "    description=\"\"\"\n",
    "    Advanced image generation with optimized settings for professional results:\n",
    "    - Enhanced prompt handling with automatic emphasis adjustment\n",
    "    - Comprehensive negative prompts to prevent common issues\n",
    "    - Advanced quality control and guidance scaling\n",
    "    - Optimized for preventing duplications and deformities\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNr+L+om4TC+n5NaeUTNaOX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
