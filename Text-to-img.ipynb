{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7TKfwkldkFV"
   },
   "outputs": [],
   "source": [
    "pip install transformers xFormers diffusers pillow opencv-python numpy gradio torch==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "booFOcBFTA_F"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riaOaXETvZv8"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade fastai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXqHMQZPdFmu"
   },
   "outputs": [],
   "source": [
    "# Higher model\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Use Stable Diffusion 2.1 (More Compatible with Diffusers)\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "# Load the Stable Diffusion model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "# Enable optimizations\n",
    "pipe.enable_attention_slicing()\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.unet = torch.compile(pipe.unet)\n",
    "\n",
    "# Function to generate an image\n",
    "def generate_image(prompt, steps, guidance):\n",
    "    image = pipe(prompt, num_inference_steps=steps, guidance_scale=guidance).images[0]\n",
    "    return image\n",
    "\n",
    "# Launch Gradio UI with debug mode\n",
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter Prompt\"),\n",
    "        gr.Slider(10, 30, value=20, step=1, label=\"Inference Steps\"),\n",
    "        gr.Slider(1, 10, value=5, step=0.5, label=\"Guidance Scale\")\n",
    "    ],\n",
    "    outputs=\"image\"\n",
    ").launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e_9_buGxtBj"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ").to(device)\n",
    "\n",
    "pipe.enable_attention_slicing()\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.unet = torch.compile(pipe.unet)\n",
    "\n",
    "def generate_image(prompt, steps=30, guidance=7.5):\n",
    "    # Add negative prompt for better results\n",
    "    negative_prompt = \"ugly, blurry, bad quality, distorted, deformed, low resolution\"\n",
    "\n",
    "    # Generate image with fixed size and improved parameters\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        width=1000,\n",
    "        height=1000\n",
    "    ).images[0]\n",
    "    return image\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter Prompt\"),\n",
    "        gr.Slider(20, 50, value=30, step=1, label=\"Inference Steps\"),  # Increased default steps\n",
    "        gr.Slider(1, 20, value=7.5, step=0.5, label=\"Guidance Scale\")  # Wider range, better default\n",
    "    ],\n",
    "    outputs=\"image\"\n",
    ").launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDXW-G08sjcZ"
   },
   "outputs": [],
   "source": [
    "# Main build\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import gradio as gr\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None\n",
    ").to(device)\n",
    "\n",
    "pipe.enable_attention_slicing()\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.enable_vae_slicing()\n",
    "def generate_image(prompt, steps=30, guidance=7.5):\n",
    "    # Enhanced negative prompt for better results\n",
    "    negative_prompt = \"ugly, blurry, bad quality, distorted, deformed, low resolution, worst quality, low quality, jpeg artifacts, watermark, text, signature, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, bad faces, broken arm and legs, deformed body, duplicated faces, duplicate, cloned objects, bad lighting, bad shading, bad colors, bad composition, bad contrast, bad saturation, bad hue, bad brightness, bad exposure, bad shadows, bad highlights, bad midtones, bad white balance, bad focus, bad framing, bad cropping, bad angle, bad perspective, bad lens, bad camera, bad camera settings, bad camera angle, bad camera lens, bad camera focus, bad camera exposure, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera white balance, bad camera settings, bad camera lighting, bad camera shadows, bad camera highlights, bad camera midtones, bad camera saturation, bad camera hue, bad camera brightness, bad camera contrast, bad camera colors, bad camera composition, bad camera shading, bad camera lighting, bad camera focus, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera lens, bad camera exposure, bad camera white balance, bad camera settings, bad camera angle, bad camera lens, bad camera focus, bad camera exposure, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera white balance, bad camera settings, bad camera lighting, bad camera shadows, bad camera highlights, bad camera midtones, bad camera saturation, bad camera hue, bad camera brightness, bad camera contrast, bad camera colors, bad camera composition, bad camera shading, bad camera lighting, bad camera focus, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera lens, bad camera exposure, bad camera white balance, bad camera settings, bad camera angle, bad camera lens, bad camera focus, bad camera exposure, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera white balance, bad camera settings, bad camera lighting, bad camera shadows, bad camera highlights, bad camera midtones, bad camera saturation, bad camera hue, bad camera brightness, bad camera contrast, bad camera colors, bad camera composition, bad camera shading, bad camera lighting, bad camera focus, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera lens, bad camera exposure, bad camera white balance, bad camera settings, bad camera angle, bad camera lens, bad camera focus, bad camera exposure, bad camera framing, bad camera cropping, bad camera angle, bad camera perspective, bad camera white balance, bad camera settings, bad camera lighting, bad camera shadows, bad camera highlights\"\n",
    "\n",
    "    # Generate image with improved parameters\n",
    "    image = pipe(\n",
    "        prompt + \", high quality, detailed, sharp focus, professional, accurate, clear, realistic, high resolution, high definition, high res, high def\",\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        width=768,\n",
    "        height=768\n",
    "    ).images[0]\n",
    "    return image\n",
    "    return image\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter Prompt\"),\n",
    "        gr.Slider(20, 50, value=30, step=1, label=\"Inference Steps\"),  # Increased default steps\n",
    "        gr.Slider(1, 20, value=7.5, step=0.5, label=\"Guidance Scale\")  # Wider range, better default\n",
    "    ],\n",
    "    outputs=\"image\"\n",
    ").launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSHxC89dxgcb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNr+L+om4TC+n5NaeUTNaOX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
